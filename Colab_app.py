# ============================================
# âš™ï¸ Colab ìë™ PDF íŒŒì‹± + JSON ë‹¤ìš´ë¡œë“œ ë²„ì „
# ============================================

# 1ï¸âƒ£ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
!apt -y install poppler-utils
!pip install paddleocr paddlepaddle-gpu
!pip install pdf2image Pillow pytesseract
!pip install langchain langchain-community langchain-huggingface
!pip install transformers accelerate sentence-transformers
!pip install sqlalchemy alembic python-dotenv tqdm

# 2ï¸âƒ£ í”„ë¡œì íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ì—…ë°ì´íŠ¸
import os
%cd /content
repo_url = "https://github.com/junki886-ops/cert-study-app.git"
if not os.path.exists("cert-study-app"):
    !git clone {repo_url}
else:
    %cd cert-study-app
    !git pull
%cd /content/cert-study-app

# 3ï¸âƒ£ ë°ì´í„° í´ë” ì¤€ë¹„
!mkdir -p data/uploads data/images data/outputs

# 4ï¸âƒ£ DB ì´ˆê¸°í™”
from pdf_parser import init_db
init_db()

# 5ï¸âƒ£ PDF ì—…ë¡œë“œ
from google.colab import files
uploaded = files.upload()
pdf_path = list(uploaded.keys())[0]
pdf_full_path = f"/content/cert-study-app/data/uploads/{pdf_path}"
print(f"[INFO] ì—…ë¡œë“œ ì™„ë£Œ: {pdf_full_path}")

# 6ï¸âƒ£ OCR + LLM íŒŒì‹± ì‹¤í–‰
from pdf_parser import parse_pdf

results = parse_pdf(
    pdf_path=pdf_full_path,
    output_json="/content/cert-study-app/data/outputs/questions.json",
    use_llm=True,      # OCR + LLM íŒŒì‹±
    lang="korean"      # í•œê¸€ OCR
)

print(f"âœ… íŒŒì‹± ì™„ë£Œ: ì´ {len(results)}ë¬¸í•­ ì¶”ì¶œë¨")

# 7ï¸âƒ£ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
import json
with open("/content/cert-study-app/data/outputs/questions.json", "r", encoding="utf-8") as f:
    data = json.load(f)

print(f"\nğŸ“˜ ì´ {len(data)}ë¬¸í•­ ì¤‘ ì• 2ë¬¸í•­ ë¯¸ë¦¬ë³´ê¸° â†“\n")
print(json.dumps(data[:2], ensure_ascii=False, indent=2))

# 8ï¸âƒ£ JSON ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
from google.colab import files
files.download("/content/cert-study-app/data/outputs/questions.json")

print("\nâœ… JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œê°€ ì‹œì‘ë©ë‹ˆë‹¤.")
